{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1j7c-rG0slK1ixpWxOctTz6KZFmYMTLiJ","timestamp":1679348131798},{"file_id":"1bhTU8Tb1ZGWYEJXoyg_c7EN_ZoDeBwmb","timestamp":1679290158027},{"file_id":"1NOULIod93elWHTKCzEIG-MlDpsz8IJld","timestamp":1679224278454}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"de60a8d2d25e4598a685e695e779bffa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdb5d0190ef94abdaca09644acff8c9e","IPY_MODEL_64a4c13e04ea4876881aa8c50ecbd94b","IPY_MODEL_59120dd89e864361ab9c79c2f2c5d355"],"layout":"IPY_MODEL_f2915168b1444c978d647cb8ae957fbf"}},"fdb5d0190ef94abdaca09644acff8c9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c290c0570e741f9969091d73b6098b1","placeholder":"​","style":"IPY_MODEL_0cafed9b0b67499b8b05cd5bfe57353b","value":"Downloading (…)okenizer_config.json: 100%"}},"64a4c13e04ea4876881aa8c50ecbd94b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2ac27e7202a497ba57fa7edcef76a6c","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3805680f6b3d4e4cb6782755b8d203e1","value":28}},"59120dd89e864361ab9c79c2f2c5d355":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39745370f0a3429ebb24f979888c739a","placeholder":"​","style":"IPY_MODEL_64255af5ac444d47aff0a4e14881e47d","value":" 28.0/28.0 [00:00&lt;00:00, 1.17kB/s]"}},"f2915168b1444c978d647cb8ae957fbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c290c0570e741f9969091d73b6098b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cafed9b0b67499b8b05cd5bfe57353b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2ac27e7202a497ba57fa7edcef76a6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3805680f6b3d4e4cb6782755b8d203e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39745370f0a3429ebb24f979888c739a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64255af5ac444d47aff0a4e14881e47d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e84351bda92e449e9923bc2b069be873":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c102d8c0834045a7aeff7d73c8151ca7","IPY_MODEL_d1948f4782ae4bc782941541f2d76ef8","IPY_MODEL_cbe2d39bd7c04bf58497dfeda7d2cdbd"],"layout":"IPY_MODEL_330412937178437b9f51f65f37c46aae"}},"c102d8c0834045a7aeff7d73c8151ca7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f6f3b0c6ba8474b95b7a806bf75e0cb","placeholder":"​","style":"IPY_MODEL_cec176b4d9144bc5a9cbd393a116e737","value":"Downloading (…)lve/main/config.json: 100%"}},"d1948f4782ae4bc782941541f2d76ef8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b965efb33964136a8f43a3d5f5ad00b","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_699f330ce931447b92cb2f414a5aa119","value":570}},"cbe2d39bd7c04bf58497dfeda7d2cdbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_759f5ffdb6d04ca593e3ed357b3d220f","placeholder":"​","style":"IPY_MODEL_eeb209a7199a460fa610fc4d5806edd7","value":" 570/570 [00:00&lt;00:00, 27.5kB/s]"}},"330412937178437b9f51f65f37c46aae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f6f3b0c6ba8474b95b7a806bf75e0cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec176b4d9144bc5a9cbd393a116e737":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b965efb33964136a8f43a3d5f5ad00b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"699f330ce931447b92cb2f414a5aa119":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"759f5ffdb6d04ca593e3ed357b3d220f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeb209a7199a460fa610fc4d5806edd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1d5663a0af64660a11758298a0f31ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5dbc14585bf943429b3940662addba9c","IPY_MODEL_d47c9347374447ecb5a4fdf6faa7ad50","IPY_MODEL_e082a105320946dcaf9aa45174089f5a"],"layout":"IPY_MODEL_cf1b916a5c974d3ba28b5dfa6daeac77"}},"5dbc14585bf943429b3940662addba9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e24d2d931d5c45e68c193b1e9b080495","placeholder":"​","style":"IPY_MODEL_c626f95a4f6841cd948102d0ad2b61fd","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"d47c9347374447ecb5a4fdf6faa7ad50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_111a73dad59048f5aa27f45c5b3492be","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e6a3d65390a4934a39fb5e09c803a8a","value":231508}},"e082a105320946dcaf9aa45174089f5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4771a2e0f4348dea42e111541cc7044","placeholder":"​","style":"IPY_MODEL_6ea297933dee4ae8bf7588824a015d13","value":" 232k/232k [00:00&lt;00:00, 3.97MB/s]"}},"cf1b916a5c974d3ba28b5dfa6daeac77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e24d2d931d5c45e68c193b1e9b080495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c626f95a4f6841cd948102d0ad2b61fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"111a73dad59048f5aa27f45c5b3492be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e6a3d65390a4934a39fb5e09c803a8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4771a2e0f4348dea42e111541cc7044":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea297933dee4ae8bf7588824a015d13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58a05fb33d8a4baa8a3601c53265b96b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29123c7102bf46729afbba43f4dc7e78","IPY_MODEL_9e61501067524998903887d30c97747b","IPY_MODEL_eb7f5872d19c491492a5539abbd63bf5"],"layout":"IPY_MODEL_968ec96beedd4cddb3c62fd1a181fd46"}},"29123c7102bf46729afbba43f4dc7e78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d248e8d66fc64d36b111d2ce061400e4","placeholder":"​","style":"IPY_MODEL_645ddbdb02fd4aec90d9aec823940273","value":"Downloading (…)/main/tokenizer.json: 100%"}},"9e61501067524998903887d30c97747b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_890a64275af6479f8b344429ad4bf35b","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2da6882e7b24e3eb145e98505a841f7","value":466062}},"eb7f5872d19c491492a5539abbd63bf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_694accecd50e46f4b2a937dd4726fb5a","placeholder":"​","style":"IPY_MODEL_425bbbc88bba41a8808218cbcd8d0355","value":" 466k/466k [00:00&lt;00:00, 4.91MB/s]"}},"968ec96beedd4cddb3c62fd1a181fd46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d248e8d66fc64d36b111d2ce061400e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"645ddbdb02fd4aec90d9aec823940273":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"890a64275af6479f8b344429ad4bf35b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2da6882e7b24e3eb145e98505a841f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"694accecd50e46f4b2a937dd4726fb5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"425bbbc88bba41a8808218cbcd8d0355":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfa7898ed17647589f79ed71db0a7076":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed63a55e7feb45cd97a743232d9c1485","IPY_MODEL_3002c3b01a9b4e549746aba93f2787fa","IPY_MODEL_876f4b8851b140d49ccb0d256ba097ef"],"layout":"IPY_MODEL_cca7abbc2fd0441ab738d43893b574e5"}},"ed63a55e7feb45cd97a743232d9c1485":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc50d6331e6b4ef0874a0a26cce6f0af","placeholder":"​","style":"IPY_MODEL_be200ff6497d447fab8e17e77efca09b","value":"Downloading pytorch_model.bin: 100%"}},"3002c3b01a9b4e549746aba93f2787fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a337b233b45e456cbcecb778f0fbc561","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5adbecc280c34cdd8ad38bf21ab06e6b","value":440473133}},"876f4b8851b140d49ccb0d256ba097ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_708f5eb3a20f451ca64073af58eef215","placeholder":"​","style":"IPY_MODEL_5b813e0f44594404a4faefe6010ba5a3","value":" 440M/440M [00:04&lt;00:00, 103MB/s]"}},"cca7abbc2fd0441ab738d43893b574e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc50d6331e6b4ef0874a0a26cce6f0af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be200ff6497d447fab8e17e77efca09b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a337b233b45e456cbcecb778f0fbc561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5adbecc280c34cdd8ad38bf21ab06e6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"708f5eb3a20f451ca64073af58eef215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b813e0f44594404a4faefe6010ba5a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcCALF9iaRHJ","executionInfo":{"status":"ok","timestamp":1680584831649,"user_tz":-330,"elapsed":21305,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"91aff796-96ab-4bcc-9e6f-d4144ad4c1f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install multimodal-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KacNDnPCIz4g","executionInfo":{"status":"ok","timestamp":1680584872394,"user_tz":-330,"elapsed":40749,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"c0d3b23e-2509-4f00-fdcc-d0ce95984aff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting multimodal-transformers\n","  Downloading multimodal_transformers-0.2a0-py3-none-any.whl (22 kB)\n","Collecting numpy~=1.21.6\n","  Downloading numpy-1.21.6-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn~=1.0.2\n","  Downloading scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy~=1.7.3\n","  Downloading scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.8/39.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting networkx~=2.6.3\n","  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas~=1.3.5\n","  Downloading pandas-1.3.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytest~=7.2.2 in /usr/local/lib/python3.9/dist-packages (from multimodal-transformers) (7.2.2)\n","Collecting tqdm~=4.64.1\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacremoses~=0.0.53\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.9/dist-packages (from multimodal-transformers) (2.0.0+cu118)\n","Collecting transformers>=4.26.1\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas~=1.3.5->multimodal-transformers) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas~=1.3.5->multimodal-transformers) (2.8.2)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest~=7.2.2->multimodal-transformers) (2.0.1)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest~=7.2.2->multimodal-transformers) (2.0.0)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest~=7.2.2->multimodal-transformers) (1.0.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest~=7.2.2->multimodal-transformers) (22.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pytest~=7.2.2->multimodal-transformers) (23.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest~=7.2.2->multimodal-transformers) (1.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacremoses~=0.0.53->multimodal-transformers) (2022.10.31)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses~=0.0.53->multimodal-transformers) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses~=0.0.53->multimodal-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses~=0.0.53->multimodal-transformers) (1.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn~=1.0.2->multimodal-transformers) (3.1.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.1->multimodal-transformers) (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.1->multimodal-transformers) (3.10.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.1->multimodal-transformers) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.1->multimodal-transformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.1->multimodal-transformers) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.13.1->multimodal-transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.13.1->multimodal-transformers) (16.0.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.26.1->multimodal-transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers>=4.26.1->multimodal-transformers) (2.27.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.13.1->multimodal-transformers) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.13.1->multimodal-transformers) (1.3.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=25e0dce9e42ba38b2a8e8cd999cf40e5dd9fafc703642a319fddceefbc45fdba\n","  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, tqdm, numpy, networkx, scipy, sacremoses, pandas, huggingface-hub, transformers, scikit-learn, multimodal-transformers\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.65.0\n","    Uninstalling tqdm-4.65.0:\n","      Successfully uninstalled tqdm-4.65.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.0\n","    Uninstalling networkx-3.0:\n","      Successfully uninstalled networkx-3.0\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.4.4\n","    Uninstalling pandas-1.4.4:\n","      Successfully uninstalled pandas-1.4.4\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.6 which is incompatible.\n","arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.13.3 multimodal-transformers-0.2a0 networkx-2.6.3 numpy-1.21.6 pandas-1.3.5 sacremoses-0.0.53 scikit-learn-1.0.2 scipy-1.7.3 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.27.4\n"]}]},{"cell_type":"code","source":["from dataclasses import dataclass, field\n","import json\n","import logging\n","import os\n","from typing import Optional\n","\n","import numpy as np\n","import pandas as pd\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig,\n","    Trainer,\n","    EvalPrediction,\n","    set_seed\n",")\n","from transformers.training_args import TrainingArguments\n","\n","from multimodal_transformers.data import load_data_from_folder\n","from multimodal_transformers.model import TabularConfig\n","from multimodal_transformers.model import AutoModelWithTabular\n","\n","logging.basicConfig(level=logging.INFO)\n","os.environ['COMET_MODE'] = 'DISABLED'"],"metadata":{"id":"K00AZB93I0eN","executionInfo":{"status":"ok","timestamp":1680584883697,"user_tz":-330,"elapsed":11307,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JgvZVR-gN5RK","executionInfo":{"status":"ok","timestamp":1680584883697,"user_tz":-330,"elapsed":19,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","if torch.cuda.is_available():    \n","    print(\"GPU Available, using GPU \\n\")\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"MVanjaXTcIgw","executionInfo":{"status":"ok","timestamp":1680584883697,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de5dcc95-b473-401c-c29e-7917e3eae8b6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Available, using GPU \n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","dataset_dir_path = 'drive/MyDrive/BTP/intentconan.csv'\n","# columns = [\"CounterSpeech\", \"HateSpeech\" , \"Relevance\", \"Aggressive\", \"Suggest\", \"Complexity, \"\"]\n","data_df = pd.read_csv(dataset_dir_path)\n","data_df['Aggressive'] = data_df['Aggressive'].apply(lambda x: x-1)\n","data_df['Relevance'] = data_df['Relevance'].apply(lambda x: x-1)\n","data_df['Complexity'] = data_df['Complexity'].apply(lambda x: x-1)\n","data_df['Length'] = data_df['Length'].apply(lambda x: x-1)\n","data_df['Suggest'] = data_df['Suggest'].apply(lambda x: x-1)\n","data_df.drop(columns=[\"Annotator\"], inplace=True)\n","data_df.dropna(inplace=True)\n","\n","# data_df['Relevance'] = data_df['Relevance'].apply(lambda x: 1.0 if x == 2.0 or x == 3.0 else (2.0 if x == 4.0 or x == 5.0 else 0.0))\n","data_df.head(100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"Y6yuM6SwcOKO","executionInfo":{"status":"ok","timestamp":1680584884393,"user_tz":-330,"elapsed":713,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"34580028-a5d1-4350-d383-bb331116ddaf"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           HateSpeech       Intent  \\\n","0   Maybe the UN could talk to those asian and afr...  Informative   \n","1   Maybe the UN could talk to those asian and afr...  Questioning   \n","2   Maybe the UN could talk to those asian and afr...   Denouncing   \n","3   Maybe the UN could talk to those asian and afr...     Positive   \n","4   ‘Juice (Jews) are worse that nukes.’ Caption t...  Informative   \n","..                                                ...          ...   \n","95  Pakistan: 202 Million Nigeria: 193 Million Ban...     Positive   \n","96  Took this in Wanstead, east London. An area wi...  Informative   \n","97  Took this in Wanstead, east London. An area wi...  Questioning   \n","98  Took this in Wanstead, east London. An area wi...   Denouncing   \n","99  Took this in Wanstead, east London. An area wi...     Positive   \n","\n","                                        CounterSpeech  Suggest  Relevance  \\\n","0   The US is the second most polluting country in...      2.0        3.0   \n","1   Doesn't everyone on the planet have a responsi...      2.0        2.0   \n","2   The world would be a better place if people we...      0.0        0.0   \n","3   You're right, ocean pollution is one of the ma...      2.0        3.0   \n","4   Anti-semitism is a serious problem that we nee...      1.0        2.0   \n","..                                                ...      ...        ...   \n","95  These groups tend to be a minority in Britian....      2.0        3.0   \n","96  There are more than enough empty homes in this...      2.0        4.0   \n","97  Is it due to immigration, or the lack of affor...      2.0        3.0   \n","98  There are so many empty homes in our country t...      2.0        4.0   \n","99  Asylum seekers and refugees deserve our compas...      1.0        2.0   \n","\n","    Aggressive  Complexity  Length  \n","0          1.0         2.0     1.0  \n","1          1.0         1.0     1.0  \n","2          1.0         1.0     0.0  \n","3          1.0         1.0     1.0  \n","4          1.0         1.0     1.0  \n","..         ...         ...     ...  \n","95         2.0         1.0     1.0  \n","96         2.0         3.0     2.0  \n","97         2.0         2.0     1.0  \n","98         3.0         3.0     2.0  \n","99         1.0         1.0     0.0  \n","\n","[100 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-9f56da13-805e-44b7-ac22-13b901ebadf3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HateSpeech</th>\n","      <th>Intent</th>\n","      <th>CounterSpeech</th>\n","      <th>Suggest</th>\n","      <th>Relevance</th>\n","      <th>Aggressive</th>\n","      <th>Complexity</th>\n","      <th>Length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Maybe the UN could talk to those asian and afr...</td>\n","      <td>Informative</td>\n","      <td>The US is the second most polluting country in...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Maybe the UN could talk to those asian and afr...</td>\n","      <td>Questioning</td>\n","      <td>Doesn't everyone on the planet have a responsi...</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Maybe the UN could talk to those asian and afr...</td>\n","      <td>Denouncing</td>\n","      <td>The world would be a better place if people we...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maybe the UN could talk to those asian and afr...</td>\n","      <td>Positive</td>\n","      <td>You're right, ocean pollution is one of the ma...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>‘Juice (Jews) are worse that nukes.’ Caption t...</td>\n","      <td>Informative</td>\n","      <td>Anti-semitism is a serious problem that we nee...</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>Pakistan: 202 Million Nigeria: 193 Million Ban...</td>\n","      <td>Positive</td>\n","      <td>These groups tend to be a minority in Britian....</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>Took this in Wanstead, east London. An area wi...</td>\n","      <td>Informative</td>\n","      <td>There are more than enough empty homes in this...</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>Took this in Wanstead, east London. An area wi...</td>\n","      <td>Questioning</td>\n","      <td>Is it due to immigration, or the lack of affor...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>Took this in Wanstead, east London. An area wi...</td>\n","      <td>Denouncing</td>\n","      <td>There are so many empty homes in our country t...</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>Took this in Wanstead, east London. An area wi...</td>\n","      <td>Positive</td>\n","      <td>Asylum seekers and refugees deserve our compas...</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f56da13-805e-44b7-ac22-13b901ebadf3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9f56da13-805e-44b7-ac22-13b901ebadf3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9f56da13-805e-44b7-ac22-13b901ebadf3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["data_df.isnull().sum().sum()"],"metadata":{"id":"N3kKSe6Wfyq_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680584884394,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"5213ed25-f199-4d51-c6d8-445a92cbc6fe"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# train_df['Aggressive'].value_counts()\n","data_df['Relevance'].value_counts()"],"metadata":{"id":"8kikL4MdgEYb","executionInfo":{"status":"ok","timestamp":1680584884394,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b8f6b03-4cc6-45de-9851-28bc9805a94b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.0    1907\n","3.0    1874\n","1.0    1159\n","4.0     977\n","0.0     197\n","Name: Relevance, dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["counterspeech = data_df['CounterSpeech'].values\n","hatespeech = data_df['HateSpeech'].values\n","rel_labels = data_df['Relevance'].values\n","print(len(rel_labels), len(counterspeech), len(hatespeech))"],"metadata":{"id":"2ULMdsyAgEeO","executionInfo":{"status":"ok","timestamp":1680584884395,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cba3a314-7ffd-4700-92a8-2732f7df9b72"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["6114 6114 6114\n"]}]},{"cell_type":"code","source":["train_df, val_df, test_df = np.split(data_df.sample(frac=1), [int(.8*len(data_df)), int(.9 * len(data_df))])\n","print('Num examples train-val-test')\n","print(len(train_df), len(val_df), len(test_df))\n","train_df.to_csv('drive/MyDrive/BTP/train.csv')\n","val_df.to_csv('drive/MyDrive/BTP/val.csv')\n","test_df.to_csv('drive/MyDrive/BTP/test.csv')\n","\n","from google.colab import files\n","\n","# files.download('train.csv')\n","# files.download('val.csv')\n","# files.download('test.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8OaRlWUWXrh","executionInfo":{"status":"ok","timestamp":1680584884792,"user_tz":-330,"elapsed":404,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"232fd3f6-28b2-484d-f9e9-449553dab903"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples train-val-test\n","4891 611 612\n"]}]},{"cell_type":"code","source":["@dataclass\n","class ModelArguments:\n","  \"\"\"\n","  Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","  \"\"\"\n","\n","  model_name_or_path: str = field(\n","      metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","  )\n","  config_name: Optional[str] = field(\n","      default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","  )\n","  tokenizer_name: Optional[str] = field(\n","      default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","  )\n","  cache_dir: Optional[str] = field(\n","      default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n","  )\n","\n","\n","@dataclass\n","class MultimodalDataTrainingArguments:\n","  \"\"\"\n","  Arguments pertaining to how we combine tabular features\n","  Using `HfArgumentParser` we can turn this class\n","  into argparse arguments to be able to specify them on\n","  the command line.\n","  \"\"\"\n","\n","  data_path: str = field(metadata={\n","                            'help': 'the path to the csv file containing the dataset'\n","                        })\n","  column_info_path: str = field(\n","      default=None,\n","      metadata={\n","          'help': 'the path to the json file detailing which columns are text, categorical, numerical, and the label'\n","  })\n","\n","  column_info: dict = field(\n","      default=None,\n","      metadata={\n","          'help': 'a dict referencing the text, categorical, numerical, and label columns'\n","                  'its keys are text_cols, num_cols, cat_cols, and label_col'\n","  })\n","\n","  categorical_encode_type: str = field(default='ohe',\n","                                        metadata={\n","                                            'help': 'sklearn encoder to use for categorical data',\n","                                            'choices': ['ohe', 'binary', 'label', 'none']\n","                                        })\n","  numerical_transformer_method: str = field(default='yeo_johnson',\n","                                            metadata={\n","                                                'help': 'sklearn numerical transformer to preprocess numerical data',\n","                                                'choices': ['yeo_johnson', 'box_cox', 'quantile_normal', 'none']\n","                                            })\n","  task: str = field(default=\"classification\",\n","                    metadata={\n","                        \"help\": \"The downstream training task\",\n","                        \"choices\": [\"classification\", \"regression\"]\n","                    })\n","\n","  mlp_division: int = field(default=4,\n","                            metadata={\n","                                'help': 'the ratio of the number of '\n","                                        'hidden dims in a current layer to the next MLP layer'\n","                            })\n","  combine_feat_method: str = field(default='individual_mlps_on_cat_and_numerical_feats_then_concat',\n","                                    metadata={\n","                                        'help': 'method to combine categorical and numerical features, '\n","                                                'see README for all the method'\n","                                    })\n","  mlp_dropout: float = field(default=0.1,\n","                              metadata={\n","                                'help': 'dropout ratio used for MLP layers'\n","                              })\n","  numerical_bn: bool = field(default=True,\n","                              metadata={\n","                                  'help': 'whether to use batchnorm on numerical features'\n","                              })\n","  use_simple_classifier: str = field(default=True,\n","                                      metadata={\n","                                          'help': 'whether to use single layer or MLP as final classifier'\n","                                      })\n","  mlp_act: str = field(default='relu',\n","                        metadata={\n","                            'help': 'the activation function to use for finetuning layers',\n","                            'choices': ['relu', 'prelu', 'sigmoid', 'tanh', 'linear']\n","                        })\n","  gating_beta: float = field(default=0.2,\n","                              metadata={\n","                                  'help': \"the beta hyperparameters used for gating tabular data \"\n","                                          \"see https://www.aclweb.org/anthology/2020.acl-main.214.pdf\"\n","                              })\n","\n","  def __post_init__(self):\n","      assert self.column_info != self.column_info_path\n","      if self.column_info is None and self.column_info_path:\n","          with open(self.column_info_path, 'r') as f:\n","              self.column_info = json.load(f)"],"metadata":{"id":"g3ljujrBThgn","executionInfo":{"status":"ok","timestamp":1680584885308,"user_tz":-330,"elapsed":519,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["text_cols = ['HateSpeech', 'CounterSpeech','Intent']\n","# cat_cols = ['Clothing ID', 'Division Name', 'Department Name', 'Class Name']\n","numerical_cols = ['Relevance', 'Aggresive', 'Complexity', 'Length']\n","\n","column_info_dict = {\n","    'text_cols': text_cols,\n","    'num_cols': numerical_cols,\n","    'label_col': 'Suggest',\n","    'label_list': [0.0,1.0,2.0]\n","}\n","\n","\n","model_args = ModelArguments(\n","    model_name_or_path='bert-base-uncased'\n",")\n","\n","data_args = MultimodalDataTrainingArguments(\n","    data_path='drive/MyDrive/BTP/',\n","    column_info=column_info_dict,\n","    task='classification'\n",")\n","\n","training_args = TrainingArguments(\n","    output_dir=\"drive/MyDrive/BTP/logs/model_name\",\n","    logging_dir=\"drive/MyDrive/BTP/logs/runs\",\n","    overwrite_output_dir=True,\n","    do_train=True,\n","    do_eval=True,\n","    do_predict=True,\n","    per_device_train_batch_size=32,\n","    num_train_epochs=5,\n","    evaluation_strategy = \"steps\",\n","    logging_steps=25,\n",")\n","\n","set_seed(training_args.seed)"],"metadata":{"id":"uwSxVAb_UKO2","executionInfo":{"status":"ok","timestamp":1680584885308,"user_tz":-330,"elapsed":4,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n","print('Specified tokenizer: ', tokenizer_path_or_name)\n","tokenizer = AutoTokenizer.from_pretrained(\n","    tokenizer_path_or_name,\n","    cache_dir=model_args.cache_dir,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163,"referenced_widgets":["de60a8d2d25e4598a685e695e779bffa","fdb5d0190ef94abdaca09644acff8c9e","64a4c13e04ea4876881aa8c50ecbd94b","59120dd89e864361ab9c79c2f2c5d355","f2915168b1444c978d647cb8ae957fbf","2c290c0570e741f9969091d73b6098b1","0cafed9b0b67499b8b05cd5bfe57353b","c2ac27e7202a497ba57fa7edcef76a6c","3805680f6b3d4e4cb6782755b8d203e1","39745370f0a3429ebb24f979888c739a","64255af5ac444d47aff0a4e14881e47d","e84351bda92e449e9923bc2b069be873","c102d8c0834045a7aeff7d73c8151ca7","d1948f4782ae4bc782941541f2d76ef8","cbe2d39bd7c04bf58497dfeda7d2cdbd","330412937178437b9f51f65f37c46aae","7f6f3b0c6ba8474b95b7a806bf75e0cb","cec176b4d9144bc5a9cbd393a116e737","9b965efb33964136a8f43a3d5f5ad00b","699f330ce931447b92cb2f414a5aa119","759f5ffdb6d04ca593e3ed357b3d220f","eeb209a7199a460fa610fc4d5806edd7","f1d5663a0af64660a11758298a0f31ef","5dbc14585bf943429b3940662addba9c","d47c9347374447ecb5a4fdf6faa7ad50","e082a105320946dcaf9aa45174089f5a","cf1b916a5c974d3ba28b5dfa6daeac77","e24d2d931d5c45e68c193b1e9b080495","c626f95a4f6841cd948102d0ad2b61fd","111a73dad59048f5aa27f45c5b3492be","2e6a3d65390a4934a39fb5e09c803a8a","e4771a2e0f4348dea42e111541cc7044","6ea297933dee4ae8bf7588824a015d13","58a05fb33d8a4baa8a3601c53265b96b","29123c7102bf46729afbba43f4dc7e78","9e61501067524998903887d30c97747b","eb7f5872d19c491492a5539abbd63bf5","968ec96beedd4cddb3c62fd1a181fd46","d248e8d66fc64d36b111d2ce061400e4","645ddbdb02fd4aec90d9aec823940273","890a64275af6479f8b344429ad4bf35b","f2da6882e7b24e3eb145e98505a841f7","694accecd50e46f4b2a937dd4726fb5a","425bbbc88bba41a8808218cbcd8d0355"]},"id":"XPoQns0-V3Fr","executionInfo":{"status":"ok","timestamp":1680584886431,"user_tz":-330,"elapsed":1127,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"56d90187-a1fd-4315-e446-bedfb2a0554f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Specified tokenizer:  bert-base-uncased\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de60a8d2d25e4598a685e695e779bffa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e84351bda92e449e9923bc2b069be873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d5663a0af64660a11758298a0f31ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58a05fb33d8a4baa8a3601c53265b96b"}},"metadata":{}}]},{"cell_type":"code","source":["data_df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjnDuJGugddU","executionInfo":{"status":"ok","timestamp":1680584886431,"user_tz":-330,"elapsed":2,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"23793f07-0665-41ea-e601-3318b9c54305"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['HateSpeech', 'Intent', 'CounterSpeech', 'Suggest', 'Relevance',\n","       'Aggressive', 'Complexity', 'Length'],\n","      dtype='object')"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Get Datasets\n","train_dataset, val_dataset, test_dataset = load_data_from_folder(\n","    folder_path = data_args.data_path,\n","    text_cols = data_args.column_info['text_cols'],\n","    tokenizer = tokenizer,\n","    label_col=data_args.column_info['label_col'],\n","    label_list=data_args.column_info['label_list'],\n","    categorical_cols=None,\n","    numerical_cols=data_args.column_info['num_cols'],\n","    categorical_encode_type=None,\n","    sep_text_token_str=tokenizer.sep_token,\n",")"],"metadata":{"id":"mMTQtZVgV3H7","executionInfo":{"status":"ok","timestamp":1680584888455,"user_tz":-330,"elapsed":2025,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["num_labels = len(np.unique(train_dataset.labels))\n","num_labels"],"metadata":{"id":"30w1DmLEWAQv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680584888455,"user_tz":-330,"elapsed":4,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"f99eed24-b254-41b8-9424-a3ec2c920613"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["config = AutoConfig.from_pretrained(\n","        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","    )\n","tabular_config = TabularConfig(num_labels=num_labels,\n","                               numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n","                               **vars(data_args))\n","config.tabular_config = tabular_config"],"metadata":{"id":"bWfWFdtsWATG","executionInfo":{"status":"ok","timestamp":1680584888455,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["model = AutoModelWithTabular.from_pretrained(\n","        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","        config=config,\n","        cache_dir=model_args.cache_dir\n","    )"],"metadata":{"id":"bCKYWei2WAYb","colab":{"base_uri":"https://localhost:8080/","height":159,"referenced_widgets":["dfa7898ed17647589f79ed71db0a7076","ed63a55e7feb45cd97a743232d9c1485","3002c3b01a9b4e549746aba93f2787fa","876f4b8851b140d49ccb0d256ba097ef","cca7abbc2fd0441ab738d43893b574e5","bc50d6331e6b4ef0874a0a26cce6f0af","be200ff6497d447fab8e17e77efca09b","a337b233b45e456cbcecb778f0fbc561","5adbecc280c34cdd8ad38bf21ab06e6b","708f5eb3a20f451ca64073af58eef215","5b813e0f44594404a4faefe6010ba5a3"]},"executionInfo":{"status":"ok","timestamp":1680584896875,"user_tz":-330,"elapsed":8423,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"dd66a23a-a37b-43dc-82d4-efdc24675ac1"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa7898ed17647589f79ed71db0a7076"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithTabular: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertWithTabular from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertWithTabular from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertWithTabular were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'tabular_combiner.num_mlp.layers.1.weight', 'tabular_classifier.bias', 'tabular_combiner.num_bn.weight', 'tabular_combiner.num_bn.running_var', 'tabular_combiner.num_bn.running_mean', 'tabular_combiner.num_mlp.bn.0.num_batches_tracked', 'tabular_combiner.num_mlp.bn.0.running_var', 'tabular_combiner.num_mlp.layers.0.weight', 'classifier.weight', 'tabular_combiner.num_bn.bias', 'tabular_combiner.num_mlp.bn.0.running_mean', 'tabular_combiner.num_mlp.bn.0.weight', 'tabular_combiner.num_mlp.layers.1.bias', 'tabular_combiner.num_mlp.layers.0.bias', 'tabular_classifier.weight', 'tabular_combiner.num_mlp.bn.0.bias', 'tabular_combiner.num_bn.num_batches_tracked']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["item = [[-1.9141968,  -0.486645,   -1.5046495,   3.447974,    0.07784579],[-2.1495693,   0.1755497,  -1.0876646 ,  3.2793176,  -0.6566321 ]]\n","print(np.argmax(item, axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1M5QpCwXvC9b","executionInfo":{"status":"ok","timestamp":1680584896875,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"97738997-77f2-4577-dfd8-4064cd07fae8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[3 3]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aR2f0hFPvpgq","executionInfo":{"status":"ok","timestamp":1680584896875,"user_tz":-330,"elapsed":2,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy.special import softmax\n","from scipy import stats\n","from sklearn.metrics import (\n","    auc,\n","    precision_recall_curve,\n","    roc_auc_score,\n","    f1_score,\n","    confusion_matrix,\n","    matthews_corrcoef,\n",")\n","\n","def calc_classification_metrics(p: EvalPrediction):\n","  # print(p.predictions[0])\n","  # print(len(p.predictions[0]))\n","  # print('-0-------------------')\n","  # print(p.predictions[1], type(p.predictions[0]), type(p.predictions[1]), len(p.predictions), type(p.predictions))\n","\n","  # for i in range(len(p.predictions)):\n","  #   p.predictions[i] = torch.from_numpy(np_array)\n","  # pred2 = torch.tensor(p.predictions)\n","  # pred2 = [torch.from_numpy(item).float() for item in p.predictions]\n","  pred_labels = np.argmax(p.predictions[0], axis=1)\n","  # print(pred_labels)\n","  pred_scores = softmax(p.predictions[0], axis=1)\n","  print(pred_scores)\n","  labels = p.label_ids\n","  labels = [int(x) for x in labels]\n","  # print('p.label_ids \\n', p.label_ids)\n","  # if len(np.unique(labels)) == 5: \n","  #     # roc_auc_pred_score = roc_auc_score(labels, pred_scores, multi_class='ovo')\n","  #     precisions, recalls, thresholds = precision_recall_curve(labels,\n","  #                                                               pred_scores)\n","  #     fscore = (2 * precisions * recalls) / (precisions + recalls)\n","  #     fscore[np.isnan(fscore)] = 0\n","  #     ix = np.argmax(fscore)\n","  #     threshold = thresholds[ix].item()\n","  #     # pr_auc = auc(recalls, precisions)\n","  #     tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0.0, 1.0, 2.0, 3.0, 4.0]).ravel()\n","  #     result = {\n","  #         'threshold': threshold,\n","  #               'recall': recalls[ix].item(),\n","  #               'precision': precisions[ix].item(), 'f1': fscore[ix].item(),\n","  #               'tn': tn.item(), 'fp': fp.item(), 'fn': fn.item(), 'tp': tp.item()\n","  #               }\n","  # else:\n","  p_corel = stats.pearsonr(pred_labels, labels) \n","  acc = (pred_labels == labels).mean()\n","  f1 = f1_score(y_true=labels, y_pred=pred_labels, average=\"macro\")\n","  result = {\n","      \"acc\": acc,\n","      \"f1\": f1,\n","      \"avg\": (acc + f1) / 2,\n","      \"mcc\": matthews_corrcoef(labels, pred_labels),\n","      \"Pearson correlation\" : p_corel\n","  }\n","\n","  return result"],"metadata":{"id":"lPrfF6imWAa_","executionInfo":{"status":"ok","timestamp":1680585153289,"user_tz":-330,"elapsed":515,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=calc_classification_metrics,\n",")"],"metadata":{"id":"v2ePdEPdWAdl","executionInfo":{"status":"ok","timestamp":1680585156464,"user_tz":-330,"elapsed":413,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["%%time\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wJut73m_kaRd","executionInfo":{"status":"ok","timestamp":1680585606971,"user_tz":-330,"elapsed":447095,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}},"outputId":"f6710e10-0caf-4f5c-f640-a3643be22232"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='431' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [431/765 07:21 < 05:44, 0.97 it/s, Epoch 2.81/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","      <th>F1</th>\n","      <th>Avg</th>\n","      <th>Mcc</th>\n","      <th>Pearson correlation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.852000</td>\n","      <td>0.758935</td>\n","      <td>0.680851</td>\n","      <td>0.270042</td>\n","      <td>0.475447</td>\n","      <td>0.000000</td>\n","      <td>(nan, nan)</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.761500</td>\n","      <td>0.771899</td>\n","      <td>0.690671</td>\n","      <td>0.352613</td>\n","      <td>0.521642</td>\n","      <td>0.157152</td>\n","      <td>(0.23092124103955045, 7.716220746862968e-09)</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.804400</td>\n","      <td>0.691089</td>\n","      <td>0.710311</td>\n","      <td>0.430315</td>\n","      <td>0.570313</td>\n","      <td>0.286289</td>\n","      <td>(0.4206766928029626, 1.3381649637664704e-27)</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.775700</td>\n","      <td>0.719179</td>\n","      <td>0.710311</td>\n","      <td>0.464517</td>\n","      <td>0.587414</td>\n","      <td>0.292165</td>\n","      <td>(0.443180368879885, 8.774348943832753e-31)</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.719000</td>\n","      <td>0.722218</td>\n","      <td>0.711948</td>\n","      <td>0.479038</td>\n","      <td>0.595493</td>\n","      <td>0.295117</td>\n","      <td>(0.45585367112998026, 1.1034129674298044e-32)</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.712500</td>\n","      <td>0.710109</td>\n","      <td>0.672668</td>\n","      <td>0.529819</td>\n","      <td>0.601243</td>\n","      <td>0.320786</td>\n","      <td>(0.4903554296250497, 2.795177729964165e-38)</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.649000</td>\n","      <td>0.711823</td>\n","      <td>0.687398</td>\n","      <td>0.551838</td>\n","      <td>0.619618</td>\n","      <td>0.328815</td>\n","      <td>(0.4941530765168484, 6.173685510120407e-39)</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.595100</td>\n","      <td>0.802030</td>\n","      <td>0.720131</td>\n","      <td>0.489520</td>\n","      <td>0.604826</td>\n","      <td>0.315643</td>\n","      <td>(0.4589417895265467, 3.693403977131413e-33)</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>0.680600</td>\n","      <td>0.731095</td>\n","      <td>0.674304</td>\n","      <td>0.551780</td>\n","      <td>0.613042</td>\n","      <td>0.334811</td>\n","      <td>(0.5162744141800198, 6.337146121466149e-43)</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.654000</td>\n","      <td>0.715782</td>\n","      <td>0.726678</td>\n","      <td>0.500788</td>\n","      <td>0.613733</td>\n","      <td>0.333442</td>\n","      <td>(0.5007269468586282, 4.320905109149294e-40)</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>0.588200</td>\n","      <td>0.719811</td>\n","      <td>0.723404</td>\n","      <td>0.569442</td>\n","      <td>0.646423</td>\n","      <td>0.374284</td>\n","      <td>(0.5181783822808657, 2.7843558388411022e-43)</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.641400</td>\n","      <td>0.703329</td>\n","      <td>0.731588</td>\n","      <td>0.523078</td>\n","      <td>0.627333</td>\n","      <td>0.356712</td>\n","      <td>(0.5219657446466532, 5.339366391871275e-44)</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>0.494900</td>\n","      <td>0.745572</td>\n","      <td>0.711948</td>\n","      <td>0.556322</td>\n","      <td>0.634135</td>\n","      <td>0.362395</td>\n","      <td>(0.5263641364616269, 7.640356477533867e-45)</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.473100</td>\n","      <td>0.765997</td>\n","      <td>0.711948</td>\n","      <td>0.539294</td>\n","      <td>0.625621</td>\n","      <td>0.343375</td>\n","      <td>(0.4946999659592324, 4.959241767409925e-39)</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>0.438800</td>\n","      <td>0.802639</td>\n","      <td>0.715221</td>\n","      <td>0.534514</td>\n","      <td>0.624868</td>\n","      <td>0.330200</td>\n","      <td>(0.4900734164058506, 3.1245430054606166e-38)</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.391400</td>\n","      <td>0.880557</td>\n","      <td>0.726678</td>\n","      <td>0.544810</td>\n","      <td>0.635744</td>\n","      <td>0.353157</td>\n","      <td>(0.5045033938106199, 9.13357124105671e-41)</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>0.468100</td>\n","      <td>0.765409</td>\n","      <td>0.687398</td>\n","      <td>0.548949</td>\n","      <td>0.618173</td>\n","      <td>0.333385</td>\n","      <td>(0.49513567313084544, 4.16392222774833e-39)</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n","  warnings.warn(PearsonRConstantInputWarning())\n","Trainer is attempting to log a value of \"(nan, nan)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.02491493 0.11384685 0.8612381 ]\n"," [0.01912171 0.11913902 0.8617393 ]\n"," [0.14149965 0.22045992 0.63804036]\n"," ...\n"," [0.17065383 0.2281109  0.6012352 ]\n"," [0.02565249 0.10980335 0.86454415]\n"," [0.24784309 0.2311948  0.5209621 ]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.23092124103955045, 7.716220746862968e-09)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.02444072 0.10739145 0.868168  ]\n"," [0.02219998 0.11700049 0.8607995 ]\n"," [0.04182841 0.13963675 0.81853473]\n"," ...\n"," [0.04128797 0.14072727 0.81798476]\n"," [0.02359011 0.09935331 0.8770565 ]\n"," [0.05531712 0.16876392 0.77591896]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.4206766928029626, 1.3381649637664704e-27)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.08033089 0.2416177  0.6780514 ]\n"," [0.0211506  0.13921109 0.83963835]\n"," [0.04325408 0.16121605 0.79552984]\n"," ...\n"," [0.08530247 0.21701278 0.6976847 ]\n"," [0.02364761 0.11196977 0.8643826 ]\n"," [0.09962039 0.2354826  0.66489697]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.443180368879885, 8.774348943832753e-31)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.23688687 0.36636674 0.39674643]\n"," [0.02458655 0.07910284 0.89631057]\n"," [0.07036643 0.20871592 0.72091764]\n"," ...\n"," [0.20703067 0.34914273 0.4438266 ]\n"," [0.08911511 0.27432382 0.63656104]\n"," [0.17232981 0.3186364  0.50903386]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.45585367112998026, 1.1034129674298044e-32)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.03202192 0.19177394 0.77620417]\n"," [0.01186285 0.13528599 0.85285115]\n"," [0.01170283 0.09795492 0.89034224]\n"," ...\n"," [0.02565217 0.14426728 0.8300806 ]\n"," [0.01609698 0.11617196 0.86773115]\n"," [0.02173401 0.11086763 0.8673984 ]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.4903554296250497, 2.795177729964165e-38)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.16363336 0.55747926 0.27888742]\n"," [0.0157657  0.09757638 0.8866579 ]\n"," [0.03653817 0.18619506 0.7772667 ]\n"," ...\n"," [0.09337234 0.44356647 0.46306124]\n"," [0.06473301 0.38495186 0.55031514]\n"," [0.05491004 0.26287553 0.68221444]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.4941530765168484, 6.173685510120407e-39)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.1244516  0.61114335 0.26440498]\n"," [0.01003998 0.12264867 0.8673115 ]\n"," [0.01907266 0.16795488 0.81297255]\n"," ...\n"," [0.08382145 0.4877954  0.42838314]\n"," [0.02743773 0.258544   0.71401817]\n"," [0.05588576 0.35569665 0.5884176 ]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.4589417895265467, 3.693403977131413e-33)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.0536795  0.21821773 0.72810286]\n"," [0.00925959 0.03985598 0.95088434]\n"," [0.00888444 0.03286199 0.95825356]\n"," ...\n"," [0.01275314 0.03660063 0.95064634]\n"," [0.01442735 0.06520795 0.9203648 ]\n"," [0.0133367  0.0335426  0.95312077]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.5162744141800198, 6.337146121466149e-43)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.12733307 0.63251454 0.2401524 ]\n"," [0.01138999 0.07775918 0.91085076]\n"," [0.02655027 0.2246903  0.7487593 ]\n"," ...\n"," [0.08985355 0.5222896  0.3878568 ]\n"," [0.02950499 0.30902576 0.6614692 ]\n"," [0.08361843 0.46606287 0.4503188 ]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.5007269468586282, 4.320905109149294e-40)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.04451694 0.3042975  0.6511855 ]\n"," [0.0087982  0.03830443 0.9528974 ]\n"," [0.0152501  0.07089541 0.9138546 ]\n"," ...\n"," [0.01622425 0.06023818 0.9235375 ]\n"," [0.01235455 0.07029866 0.91734684]\n"," [0.10277871 0.23841843 0.65880287]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.5181783822808657, 2.7843558388411022e-43)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.09725111 0.57749003 0.32525888]\n"," [0.00489513 0.04274531 0.95235956]\n"," [0.00612595 0.05547599 0.9383981 ]\n"," ...\n"," [0.01283905 0.08164119 0.9055197 ]\n"," [0.01274225 0.1376037  0.8496541 ]\n"," [0.12643126 0.3072334  0.5663354 ]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.5219657446466532, 5.339366391871275e-44)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.07389963 0.44480002 0.4813003 ]\n"," [0.0067893  0.04878333 0.9444273 ]\n"," [0.01322588 0.08356165 0.9032124 ]\n"," ...\n"," [0.01588712 0.06590556 0.9182073 ]\n"," [0.01218872 0.09340911 0.894402  ]\n"," [0.06333508 0.17790712 0.75875777]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.5263641364616269, 7.640356477533867e-45)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.0992546  0.77788526 0.12286001]\n"," [0.00668847 0.07474814 0.9185635 ]\n"," [0.00485437 0.06953502 0.92561054]\n"," ...\n"," [0.02148838 0.15829827 0.82021326]\n"," [0.00423207 0.06997859 0.92578924]\n"," [0.14555924 0.47953016 0.37491065]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.4946999659592324, 4.959241767409925e-39)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.05744116 0.7760585  0.16650027]\n"," [0.00408209 0.02506397 0.970854  ]\n"," [0.00403342 0.03829227 0.9576743 ]\n"," ...\n"," [0.0050094  0.02657679 0.9684139 ]\n"," [0.00526343 0.06809209 0.92664456]\n"," [0.04336635 0.15828688 0.79834676]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.4900734164058506, 3.1245430054606166e-38)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.06610901 0.6890153  0.2448758 ]\n"," [0.00549188 0.02272741 0.9717806 ]\n"," [0.00830831 0.05052589 0.9411657 ]\n"," ...\n"," [0.00437224 0.01989814 0.9757296 ]\n"," [0.00406551 0.03669242 0.95924205]\n"," [0.14707512 0.36548385 0.4874411 ]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.5045033938106199, 9.13357124105671e-41)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.07297606 0.8534673  0.07355653]\n"," [0.00303122 0.01724364 0.9797252 ]\n"," [0.00279091 0.01984875 0.9773603 ]\n"," ...\n"," [0.00264884 0.01872773 0.97862345]\n"," [0.00223719 0.02820836 0.96955454]\n"," [0.01613795 0.08332454 0.9005375 ]]\n"]},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"(0.49513567313084544, 4.16392222774833e-39)\" of type <class 'tuple'> for key \"eval/Pearson correlation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.09372887 0.8204007  0.08587037]\n"," [0.00507751 0.0204829  0.9744396 ]\n"," [0.01496863 0.09679586 0.8882355 ]\n"," ...\n"," [0.00686368 0.03355608 0.9595803 ]\n"," [0.01138961 0.12611966 0.8624908 ]\n"," [0.33795592 0.5744776  0.08756647]]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         )\n\u001b[0;32m-> 1633\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtr_loss_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0;31m# Optimizer step for deepspeed must be called on every step regardless of the value of gradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \"\"\"\n\u001b[1;32m   3409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"floating_point_ops\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3410\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, input_dict, exclude_embeddings)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \"\"\"\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mnum_parameters\u001b[0;34m(self, only_trainable, exclude_embeddings)\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;34mf\"{name}.weight\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             ]\n\u001b[0;32m--> 918\u001b[0;31m             non_embedding_parameters = [\n\u001b[0m\u001b[1;32m    919\u001b[0m                 \u001b[0mparameter\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membedding_param_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;34mf\"{name}.weight\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             ]\n\u001b[0;32m--> 918\u001b[0;31m             non_embedding_parameters = [\n\u001b[0m\u001b[1;32m    919\u001b[0m                 \u001b[0mparameter\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membedding_param_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             prefix=prefix, recurse=recurse, remove_duplicate=remove_duplicate)\n\u001b[0;32m-> 2115\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_named_members\u001b[0;34m(self, get_members_fn, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2050\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2265\u001b[0;31m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2266\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"SPTHQg-IkaTp","executionInfo":{"status":"aborted","timestamp":1680584906442,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir ./logs/runs --port=6006"],"metadata":{"id":"RXvj947EThjY","executionInfo":{"status":"aborted","timestamp":1680584906442,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XP_OCLYimofN"}},{"cell_type":"code","source":[],"metadata":{"id":"YE5NMANomohs","executionInfo":{"status":"aborted","timestamp":1680584906443,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_drACdppmokN","executionInfo":{"status":"aborted","timestamp":1680584906443,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3yjTaB3Qmomn","executionInfo":{"status":"aborted","timestamp":1680584906443,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0AcGZyIcmopI","executionInfo":{"status":"aborted","timestamp":1680584906443,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-rRDdX1Hmorc","executionInfo":{"status":"aborted","timestamp":1680584906444,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2UusmJ7Rmot0","executionInfo":{"status":"aborted","timestamp":1680584906444,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5d94JbtPmowd","executionInfo":{"status":"aborted","timestamp":1680584906444,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZJZ1f5-wmoyv","executionInfo":{"status":"aborted","timestamp":1680584906444,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LxdwxPDZmo1h","executionInfo":{"status":"aborted","timestamp":1680584906444,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MNsPhszamo3i","executionInfo":{"status":"aborted","timestamp":1680584906444,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jrX3JJrLmo5j","executionInfo":{"status":"aborted","timestamp":1680584906445,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","\n","dataset = TensorDataset(input_ids, attention_masks, rel_labels)\n","\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"],"metadata":{"id":"0BGMkrTFThaX","executionInfo":{"status":"aborted","timestamp":1680584906445,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install transformers"],"metadata":{"id":"NkH6AYjBg6vH","executionInfo":{"status":"aborted","timestamp":1680584906445,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"id":"LZCkeYTEgEgv","executionInfo":{"status":"aborted","timestamp":1680584906445,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict\n","import matplotlib.pyplot as plt\n","\n","def returnZero():\n","    return 0\n","max_len = 0\n","lengths = defaultdict(returnZero)\n","for cs in counterspeech:\n","    input_ids = tokenizer.encode(str(cs), add_special_tokens=True)\n","    lengths[len(input_ids)]+=1\n","    max_len = max(max_len, len(input_ids))\n","lengths\n","\n","keys=sorted(list(lengths.keys()))\n","vals = [lengths[key] for key in keys]\n","plt.figure(figsize=(20, 20))\n","plt.plot(keys, vals)\n","plt.title('Len vs count')\n","plt.ylabel('count')\n","plt.xlabel('len')\n","plt.savefig('vis.jpg')\n","\n","# post 40-42 the count of title lengths is negligible, to avoid trailing zeroes, setting pad length to 42"],"metadata":{"id":"M1U3RAkpgEjI","executionInfo":{"status":"aborted","timestamp":1680584906445,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_pad_length = 120\n","to_pad = True"],"metadata":{"id":"3YWEGfFGgEli","executionInfo":{"status":"aborted","timestamp":1680584906445,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = []\n","attention_masks = []\n","\n","for cs in counterspeech:\n","    encoded_dict = tokenizer.encode_plus(\n","                        str(cs),                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = max_pad_length,           # Pad & truncate all sentences.\n","                        pad_to_max_length = to_pad,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","rel_labels = torch.tensor(rel_labels)"],"metadata":{"id":"Y3T1gJbYgEn0","executionInfo":{"status":"aborted","timestamp":1680584906446,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(input_ids)"],"metadata":{"id":"R23nFwmMgEqN","executionInfo":{"status":"aborted","timestamp":1680584906446,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","\n","dataset = TensorDataset(input_ids, attention_masks, rel_labels)\n","\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"],"metadata":{"id":"nXfjyYqehQK_","executionInfo":{"status":"aborted","timestamp":1680584906446,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"0NEWRttlgFGn","executionInfo":{"status":"aborted","timestamp":1680584906446,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(torch.cuda.is_available())"],"metadata":{"id":"AvrJClMpgFI0","executionInfo":{"status":"aborted","timestamp":1680584906446,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 3, # The number of output labels is 30\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","model.cuda()"],"metadata":{"id":"M-mmTXFCgUKz","executionInfo":{"status":"aborted","timestamp":1680584906446,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"metadata":{"id":"l7turA0xgUNB","executionInfo":{"status":"aborted","timestamp":1680584906446,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","# epochs experimented between 2, 3 and 4 \n","epochs = 2\n","total_steps = len(train_dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, \n","                                            num_training_steps = total_steps)"],"metadata":{"id":"zNE03gTxgUlu","executionInfo":{"status":"aborted","timestamp":1680584906447,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    print(pred_flat)\n","    print(labels_flat)\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"HxvqRepygUn0","executionInfo":{"status":"aborted","timestamp":1680584906447,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = torch.tensor([0.,2.,2.,1.,1.,1.,1.])\n","torch.nn.functional.one_hot(test.to(torch.int64), 3)"],"metadata":{"id":"Mm5p6F0wgb4g","executionInfo":{"status":"aborted","timestamp":1680584906447,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","seed_val = 66\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","for epoch_i in range(0, epochs):\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","#         b_labels = torch.nn.functional.one_hot(batch[2].to(torch.int64),5)\n","#         print(batch[2].to(torch.int64))\n","        b_labels = batch[2].to(torch.int64).to(device)\n","        model.zero_grad()      \n","#         print(b_labels)\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels,return_dict = False)\n","        total_train_loss += loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    for batch in validation_dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(torch.int64).to(device)\n","        with torch.no_grad():        \n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels,return_dict = False)\n","        total_eval_loss += loss.item()\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        print('preds',logits)\n","        print('act',label_ids)\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))"],"metadata":{"id":"OFjkD8JIgb7A","executionInfo":{"status":"aborted","timestamp":1680584906447,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j2bbI292nBoN","executionInfo":{"status":"aborted","timestamp":1680584906447,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayush Goyal","userId":"16886632502915947840"}}},"execution_count":null,"outputs":[]}]}